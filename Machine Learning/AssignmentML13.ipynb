{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Model\n",
    "\n",
    "**Since it is required a compare with a model that was developed in logistic regression assignment, I will rework on the same dataset, not Seattle Weather dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/daniel-dc-cd/data_science/master/module_3_Python/data/titanic.csv')\n",
    "\n",
    "\n",
    "numrows = 891 \n",
    "\n",
    "\n",
    "#This step just to Take the #Survived values as True and False instead of 0 and 1 \n",
    "\n",
    "RandomForest_pd = pd.DataFrame({'Survivor':[True] * numrows})\n",
    "\n",
    "#sort columns for convience\n",
    "seq = ['Survivor']\n",
    "RandomForest_pd = RandomForest_pd.reindex(columns=seq)\n",
    "\n",
    "\n",
    "for z in range(numrows):\n",
    "    #pull values from the dataframe\n",
    "    Survived = df.iloc[z,1]\n",
    "    \n",
    "    RandomForest_pd.iat[z,0] = Survived\n",
    "\n",
    "RandomForest_pd = RandomForest_pd.dropna() #exclude any r\n",
    "\n",
    "\n",
    "\n",
    "#Join regression_df with the original and delete Survived column\n",
    "\n",
    "df=df.join(RandomForest_pd)\n",
    "df.drop(columns=['Survived'], axis=1, inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode Sex Feature\n",
    "\n",
    "cat_vars = ['Sex']\n",
    "for var in cat_vars:\n",
    "    cat_list = pd.get_dummies(df[var], prefix=var)\n",
    "    df1=df.join(cat_list)\n",
    "\n",
    "    \n",
    "df1.drop(columns=['Sex'], axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Random Forests Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "x = df1[['Sex_female','Pclass']]\n",
    "y = df1['Survivor']\n",
    "\n",
    "#separate training and test sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation on Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7865168539325843\n"
     ]
    }
   ],
   "source": [
    "clf = ensemble.RandomForestClassifier(n_estimators=40).fit(X_train, y_train)\n",
    "\n",
    "#we can calculate the accuarcy using the score method\n",
    "score = clf.score(X_train,y_train)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8156424581005587\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf = ensemble.RandomForestClassifier(n_estimators=40).fit(X_test,y_test)\n",
    "\n",
    "#we can calculate the accuarcy using the score method\n",
    "score = clf.score(X_test,y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7865168539325843\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "clf1 = linear_model.LogisticRegression(solver='lbfgs').fit(X_train, y_train)\n",
    "#we can calculate the accuarcy using the score method\n",
    "score = clf1.score(X_train,y_train)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q)Use the same feature set you developed for the logistic regression assignment. How did the two perform against each other?**\n",
    "\n",
    "As we see their performance are same  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
